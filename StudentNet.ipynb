{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db367a1-a2a7-43c4-93df-d9ec29da8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from codecs import open\n",
    "\n",
    "def build_corpus(split, make_vocab=True, data_dir=\"./ResumeNER\"):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    assert split in ['train', 'dev', 'test']\n",
    "\n",
    "    word_lists = []\n",
    "    tag_lists = []\n",
    "    with open(join(data_dir, split+\".char.bmes\"), 'r', encoding='utf-8') as f:\n",
    "        word_list = []\n",
    "        tag_list = []\n",
    "        for line in f:\n",
    "            if line != '\\n':\n",
    "                word, tag = line.strip('\\n').split()\n",
    "                word_list.append(word)\n",
    "                tag_list.append(tag)\n",
    "            else:\n",
    "                word_lists.append(word_list)\n",
    "                tag_lists.append(tag_list)\n",
    "                word_list = []\n",
    "                tag_list = []\n",
    "\n",
    "    # 如果make_vocab为True，还需要返回word2id和tag2id\n",
    "    if make_vocab:\n",
    "        word2id = build_map(word_lists)\n",
    "        tag2id = build_map(tag_lists)\n",
    "        return word_lists, tag_lists, word2id, tag2id\n",
    "    else:\n",
    "        return word_lists, tag_lists\n",
    "\n",
    "\n",
    "def build_map(lists):\n",
    "    maps = {}\n",
    "    for list_ in lists:\n",
    "        for e in list_:\n",
    "            if e not in maps:\n",
    "                maps[e] = len(maps)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81f038-ff52-48bb-aa4c-d8e5ab57bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def merge_maps(dict1, dict2):\n",
    "    \"\"\"用于合并两个word2id或者两个tag2id\"\"\"\n",
    "    for key in dict2.keys():\n",
    "        if key not in dict1:\n",
    "            dict1[key] = len(dict1)\n",
    "    return dict1\n",
    "\n",
    "def save_model(model, file_name):\n",
    "    \"\"\"用于保存模型\"\"\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(file_name):\n",
    "    \"\"\"用于加载模型\"\"\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "# LSTM模型训练的时候需要在word2id和tag2id加入PAD和UNK\n",
    "# 如果是加了CRF的lstm还要加入<start>和<end> (解码的时候需要用到)\n",
    "def extend_maps(word2id, tag2id, for_crf=True):\n",
    "    word2id['<unk>'] = len(word2id)\n",
    "    word2id['<pad>'] = len(word2id)\n",
    "    tag2id['<unk>'] = len(tag2id)\n",
    "    tag2id['<pad>'] = len(tag2id)\n",
    "    # 如果是加了CRF的bilstm  那么还要加入<start> 和 <end>token\n",
    "    if for_crf:\n",
    "        word2id['<start>'] = len(word2id)\n",
    "        word2id['<end>'] = len(word2id)\n",
    "        tag2id['<start>'] = len(tag2id)\n",
    "        tag2id['<end>'] = len(tag2id)\n",
    "\n",
    "    return word2id, tag2id\n",
    "\n",
    "\n",
    "def prepocess_data_for_lstmcrf(word_lists, tag_lists, test=False):\n",
    "    assert len(word_lists) == len(tag_lists)\n",
    "    for i in range(len(word_lists)):\n",
    "        word_lists[i].append(\"<end>\")\n",
    "        if not test:  # 如果是测试数据，就不需要加end token了\n",
    "            tag_lists[i].append(\"<end>\")\n",
    "\n",
    "    return word_lists, tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96565a-2bce-441b-9968-d5924cbe7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from models.hmm import HMM\n",
    "from models.crf import CRFModel\n",
    "from models.bilstm_crf import BILSTM_Model\n",
    "from utils import save_model, flatten_lists\n",
    "from evaluating import Metrics\n",
    "def ensemble_evaluate(results, targets, remove_O=False):\n",
    "    \"\"\"ensemble多个模型\"\"\"\n",
    "    for i in range(len(results)):\n",
    "        results[i] = flatten_lists(results[i])\n",
    "\n",
    "    pred_tags = []\n",
    "    for result in zip(*results):\n",
    "        ensemble_tag = Counter(result).most_common(1)[0][0]\n",
    "        pred_tags.append(ensemble_tag)\n",
    "\n",
    "    targets = flatten_lists(targets)\n",
    "    assert len(pred_tags) == len(targets)\n",
    "\n",
    "    print(\"Ensemble 四个模型的结果如下：\")\n",
    "    metrics = Metrics(targets, pred_tags, remove_O=remove_O)\n",
    "    metrics.report_scores()\n",
    "    metrics.report_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae5d87-1493-4185-9098-330ef0fccece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 读取数据\n",
    "    print(\"读取数据...\")\n",
    "    train_word_lists, train_tag_lists, word2id, tag2id = build_corpus(\"train\")\n",
    "    dev_word_lists, dev_tag_lists = build_corpus(\"dev\", make_vocab=False)\n",
    "    test_word_lists, test_tag_lists = build_corpus(\"test\", make_vocab=False)\n",
    "    \n",
    "    \"\"\"训练模型，评估结果\"\"\"\n",
    "    print(\"正在训练评估Bi-LSTM+CRF模型...\")\n",
    "    # 如果是加了CRF的lstm还要加入<start>和<end> (解码的时候需要用到)\n",
    "    crf_word2id, crf_tag2id = extend_maps(word2id, tag2id, for_crf=True)\n",
    "    # 还需要额外的一些数据处理\n",
    "    train_word_lists, train_tag_lists = prepocess_data_for_lstmcrf(\n",
    "        train_word_lists, train_tag_lists\n",
    "    )\n",
    "    dev_word_lists, dev_tag_lists = prepocess_data_for_lstmcrf(\n",
    "        dev_word_lists, dev_tag_lists\n",
    "    )\n",
    "    test_word_lists, test_tag_lists = prepocess_data_for_lstmcrf(\n",
    "        test_word_lists, test_tag_lists, test=True\n",
    "    )\n",
    "    lstmcrf_pred = bilstm_train_and_eval(\n",
    "        (train_word_lists, train_tag_lists),\n",
    "        (dev_word_lists, dev_tag_lists),\n",
    "        (test_word_lists, test_tag_lists),\n",
    "        crf_word2id, crf_tag2id\n",
    "    )\n",
    "\n",
    "    ensemble_evaluate(\n",
    "        [hmm_pred, crf_pred, lstm_pred, lstmcrf_pred],\n",
    "        test_tag_lists\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
