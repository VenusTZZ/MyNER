{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e23fa5c-895b-4e1c-a90c-f5dd7c91a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-crf\n",
    "# !pip install seqeval\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2febb544-dc5b-443a-909c-e6fba30a26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "categories = set()\n",
    "\n",
    "class ReadData(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        Data = {}\n",
    "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
    "            for idx, line in enumerate(f.read().split('\\n\\n')):\n",
    "                if not line:\n",
    "                    break\n",
    "                sentence, tags = '', []\n",
    "                for i, c in enumerate(line.split('\\n')):\n",
    "                    word, tag = c.split('\\t')\n",
    "                    if word==' ':\n",
    "                        word='1'\n",
    "                    sentence += word\n",
    "                    if tag[0] == 'B':\n",
    "                        tags.append([i, i, word, tag[2:]]) # Remove the B- or I-\n",
    "                        # print(tags)\n",
    "                        categories.add(tag[2:])\n",
    "                    elif tag[0] == 'I':\n",
    "                        # print(tags)\n",
    "                        # print(word)\n",
    "                        # print(tag)\n",
    "                        tags[-1][1] = i\n",
    "                        tags[-1][2] += word\n",
    "                Data[idx] = {\n",
    "                    'sentence': sentence, \n",
    "                    'tags': tags\n",
    "                }\n",
    "        return Data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c938bf-e59f-4530-8fef-133e46a59f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '主机厂家已机组提供高电压耐受能力情况说明，未说明具体耐受能力范围，，缺少对应的报告文件支持。能效技术监督。3.常用标准、规程、措施、制度、技术资料和各种记录缺失。主机厂家已提供符合要求的高电压耐受能力证明报告及对应的支持文件', 'tags': [[0, 31, '主机厂家已机组提供高电压耐受能力情况说明，未说明具体耐受能力范围', 'Pro'], [34, 44, '缺少对应的报告文件支持', 'Cau'], [74, 79, '各种记录缺失', 'Cau'], [81, 111, '主机厂家已提供符合要求的高电压耐受能力证明报告及对应的支持文件', 'Met']]}\n"
     ]
    }
   ],
   "source": [
    "train_data = ReadData('./example.train')\n",
    "valid_data = ReadData('./example.dev')\n",
    "# test_data = ReadData('./example.test')\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db15345-5245-4fe5-a8da-feb161c4c5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cau', 'Met', 'Pro'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248141e9-424b-44bd-9d07-c8e6a2b99db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-Cau', 2: 'I-Cau', 3: 'B-Met', 4: 'I-Met', 5: 'B-Pro', 6: 'I-Pro'}\n",
      "{'O': 0, 'B-Cau': 1, 'I-Cau': 2, 'B-Met': 3, 'I-Met': 4, 'B-Pro': 5, 'I-Pro': 6}\n"
     ]
    }
   ],
   "source": [
    "id2label = {0:'O'}\n",
    "for c in list(sorted(categories)):\n",
    "    id2label[len(id2label)] = f\"B-{c}\"\n",
    "    id2label[len(id2label)] = f\"I-{c}\"\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0250486-767b-483c-8d2c-26412e1da96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import numpy as np\n",
    "\n",
    "# checkpoint = \"bert-base-chinese\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# sentence = '主机厂家已机组提供高电压耐受能力情况说明（未说明具体耐受能力范围）'\n",
    "# tags = [[9, 13, '高电压耐受', 'Phe']]\n",
    "\n",
    "# encoding = tokenizer(sentence, truncation=True)\n",
    "# tokens = encoding.tokens()\n",
    "# label = np.zeros(len(tokens), dtype=int)\n",
    "# for char_start, char_end, word, tag in tags:\n",
    "#     token_start = encoding.char_to_token(char_start)\n",
    "#     token_end = encoding.char_to_token(char_end)\n",
    "#     label[token_start] = label2id[f\"B-{tag}\"]\n",
    "#     label[token_start+1:token_end+1] = label2id[f\"I-{tag}\"]\n",
    "\n",
    "# print(tokens)\n",
    "# print(label)\n",
    "# print([id2label[id] for id in label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f57d6ff-b11e-4ce9-95f9-8de01bce1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    # batch_sentence, batch_tags,mask = [], [], []\n",
    "    batch_sentence, batch_tags = [], []\n",
    "    for sample in batch_samples:\n",
    "        # print(sample)\n",
    "        batch_sentence.append(sample['sentence'])\n",
    "        batch_tags.append(sample['tags'])\n",
    "        # mask.append(sample['mask_tensor'])\n",
    "    batch_inputs = tokenizer(\n",
    "        batch_sentence, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\",\n",
    "        # max_length=256\n",
    "    )\n",
    "    batch_label = np.zeros(batch_inputs['input_ids'].shape, dtype=int)\n",
    "    for s_idx, sentence in enumerate(batch_sentence):\n",
    "        encoding = tokenizer(sentence, truncation=True)\n",
    "        batch_label[s_idx][0] = 0\n",
    "        batch_label[s_idx][len(encoding.tokens())-1:] = 0\n",
    "        for char_start, char_end, _, tag in batch_tags[s_idx]:\n",
    "            token_start = encoding.char_to_token(char_start)\n",
    "            token_end = encoding.char_to_token(char_end)\n",
    "            batch_label[s_idx][token_start] = label2id[f\"B-{tag}\"]\n",
    "            batch_label[s_idx][token_start+1:token_end+1] = label2id[f\"I-{tag}\"]\n",
    "    return batch_inputs, torch.tensor(batch_label)\n",
    "\n",
    "# train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collote_fn)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=collote_fn)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=4, shuffle=False, collate_fn=collote_fn)\n",
    "\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "# print('batch_X shape:', {k: v.shape for k, v in batch_X.items()})\n",
    "# print('batch_y shape:', batch_y.shape)\n",
    "# print(batch_X)\n",
    "# print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e63366-cc6a-4196-9d91-6a8c5e7bf8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint)\n",
    "        self.config = self.bert.config\n",
    "        self.BiLstm=nn.LSTM(input_size=self.config.hidden_size,hidden_size=512,batch_first=True,bidirectional=True,num_layers=2)\n",
    "        self.Linear = nn.Linear(512*2, len(id2label))\n",
    "        self.crf = CRF(len(id2label),batch_first=True)\n",
    "            \n",
    "    # def forward(self, x):\n",
    "    def forward(self, x, y):\n",
    "        # 1.\n",
    "        # output = self.bert(**x).last_hidden_state\n",
    "        # output, _ = self.BiLstm(output)\n",
    "        # output = self.Linear(output)\n",
    "        # return output\n",
    "        # 2.\n",
    "        output = self.bert(**x).last_hidden_state\n",
    "        output, _ = self.BiLstm(output)\n",
    "        output = self.Linear(output)\n",
    "        # loss = self.crf(emissions=output,tags=y,mask=mask_tensor)\n",
    "        # tag = self.crf.decode(emissions=output,,mask=mask_tensor)\n",
    "        loss = self.crf(emissions=output,tags=y)\n",
    "        tag = self.crf.decode(emissions=output)\n",
    "        tag=torch.tensor(tag)\n",
    "        return loss, tag\n",
    "    \n",
    "    def decode(self,x):\n",
    "        output = self.bert(**x).last_hidden_state\n",
    "        output, _ = self.BiLstm(output)\n",
    "        output = self.Linear(output)\n",
    "        tag = self.crf.decode(emissions=output)\n",
    "        tag=torch.tensor(tag)\n",
    "        return tag\n",
    "    \n",
    "model = model().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be8c030-7be7-4a53-a61d-1d7afe5be5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, lr_scheduler, epoch, total_loss):\n",
    "# def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader, start=1):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        loss, tag = model(X, y)\n",
    "        #  通过 pred.permute(0, 2, 1) 交换后两维，将模型预测结果从(batch,seq,7) 调整为 (batch,7,seq)。\n",
    "        # loss = loss_fn(pred.permute(0, 2, 1), y)\n",
    "        loss = abs(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a8b2e0-809d-45a6-b967-5594a3d9f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval\n",
    "# from seqeval.metrics import classification_report\n",
    "# from seqeval.scheme import IOB2\n",
    "\n",
    "# y_true = [['O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "# y_pred = [['O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "\n",
    "# print(classification_report(y_true, y_pred, mode='strict', scheme=IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476e3919-9969-4b27-9ba7-7c039681d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    true_labels, true_predictions = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # pred = model(X)\n",
    "            loss, tag = model(X, y)\n",
    "            \n",
    "            # predictions = pred.argmax(dim=-1)\n",
    "            predictions = tag\n",
    "            \n",
    "            true_labels += [[id2label[int(l)] for l in label if l != -100] for label in y]\n",
    "            true_predictions += [\n",
    "                [id2label[int(p)] for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, y)\n",
    "            ]\n",
    "    print(classification_report(true_labels, true_predictions, mode='strict', scheme=IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67e51c-ef82-44ba-a35e-f5ff354f0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca57bf036ee649029bdcb5a311c5e5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:333.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae55532499a4edbacfd543d016e8829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cau       0.00      0.00      0.00       393\n",
      "         Met       0.00      0.00      0.00       585\n",
      "         Pro       0.00      0.00      0.00       900\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      1878\n",
      "   macro avg       0.00      0.00      0.00      1878\n",
      "weighted avg       0.00      0.00      0.00      1878\n",
      "\n",
      "Epoch 2/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ecfa149e4047ddba7ca013ec2c141d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27ffbb6ee374afabbf85f2f5180a9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301612aa29034914a0dd2f73368b94f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cde2dbdc624b4bb30bd17e346a16a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c6ad6e037a49ceb8bc3e93bf2cb20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be086cc5fac3460086df5e3fa1d6254b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f5ed1d736041ec8af7d19361aa7717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39afda00fffd4cb19fb1f3dce3482854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4b183fe20b4d7fbd9674ae3d8595a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0e34dc380340029e0cdcea9b4fa674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc251ba2dbf4848a4b04906eca856de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cau       0.00      0.00      0.00       393\n",
      "         Met       0.00      0.00      0.00       585\n",
      "         Pro       0.00      0.00      0.00       900\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      1878\n",
      "   macro avg       0.00      0.00      0.00      1878\n",
      "weighted avg       0.00      0.00      0.00      1878\n",
      "\n",
      "Epoch 12/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b160af5aa134eeabaf16d3e52d03421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e724020a7a0e4d719ebd86078db21f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6781413bc2d54ad5973324c87499d3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572c65c35c164984af3d7ce1b704649c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd559c4f17014bf88298529df104513f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e5c92135b64ff585e0a249ee3419ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784066ae0a3841b2a2262c981de454dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3d28de40364a25ba32ce210993e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c834381c48b04add8fcc866a1b558579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815945e4c2684d468acb5117685326b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4ce4b96b9249b9a89c87f0ab8d976c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cau       0.00      0.00      0.00       393\n",
      "         Met       0.00      0.00      0.00       585\n",
      "         Pro       0.00      0.00      0.00       900\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      1878\n",
      "   macro avg       0.00      0.00      0.00      1878\n",
      "weighted avg       0.00      0.00      0.00      1878\n",
      "\n",
      "Epoch 22/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77f437d550e40d3b55ede4b73c5b36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ae620e06f143ab8be1882b14e5402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3919c6c38c468bace35decf4cfae5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444e3f3f1cb04bd1b0ae3ec497dd1560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29c7812fbbd488a9e78bfc9d6e1eec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e74b66058b0418c900f57ecb612585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75777f06d742461f9fbba4e7cb952975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37c5b750eb74bd69f2321caf9cc58bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91696cfb274e4502ac434e732d4ce7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a59466692c4f699f6553814ce26c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4765beaddd15491e8122d5319ffe2198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cau       0.00      0.00      0.00       393\n",
      "         Met       0.00      0.00      0.00       585\n",
      "         Pro       0.73      0.23      0.35       900\n",
      "\n",
      "   micro avg       0.73      0.11      0.19      1878\n",
      "   macro avg       0.24      0.08      0.12      1878\n",
      "weighted avg       0.35      0.11      0.17      1878\n",
      "\n",
      "Epoch 32/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34202249546d4b45a121337e88def6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc688c3321f4afbbe27d1d83d03df36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c34d9e46d7d428687bf83a2fba42c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cc16b5d3824b0e9208e4fe69cfcf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5ea034490c4109811855f4372a9ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa1fc863e8d4503aa55ad42a93040df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df528482304521bb041983f8f5305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33057ee9bb0b42eea59b52d5925af5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f5e78f8049428fa4aed863d92303a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9c44f3871d406b9e0ceac53f5ec444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b483aaa84c43b7805305e37b8bfde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epoch_num = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "loss_list=[]\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    # total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    if(t%10==0):\n",
    "        test_loop(valid_dataloader, model)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2933a6-a052-4b5c-8e01-4d0de6db55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '在使用过程中若发现油位指示窗内出现油面，说明波纹囊有渗漏，绝缘油进入空气腔。发现指示窗有油应马上通知厂家处理，并采取临时措施。'\n",
    "\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sentence, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model.decode(inputs)\n",
    "    predictions = pred[0].tolist()\n",
    "    pred_label = []\n",
    "    inputs_with_offsets = tokenizer(sentence, return_offsets_mapping=True)\n",
    "    tokens = inputs_with_offsets.tokens()\n",
    "    offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "    idx = 0\n",
    "    while idx < len(predictions):\n",
    "        pred = predictions[idx]\n",
    "        label = id2label[pred]\n",
    "        if label != \"O\":\n",
    "            label = label[2:] # Remove the B- or I-\n",
    "            start, end = offsets[idx]\n",
    "            while (\n",
    "                idx + 1 < len(predictions) and \n",
    "                id2label[predictions[idx + 1]] == f\"I-{label}\"\n",
    "            ):\n",
    "                # all_scores.append(probabilities[idx + 1][predictions[idx + 1]])\n",
    "                _, end = offsets[idx + 1]\n",
    "                idx += 1\n",
    "            word = sentence[start:end]\n",
    "            pred_label.append(\n",
    "                {\n",
    "                    \"entity_group\": label,\n",
    "                    \"word\": word,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                }\n",
    "            )\n",
    "        idx += 1\n",
    "    print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2158ba-fba9-45bd-b6c6-b40f95925551",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '气体继电器保护装置的信号动作时，值班员应立即停止报警信号，并检查变压器，查明信号动作的原因，是否因空气侵入变压器内，或是油位降低，或是二次回路故障。'\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sentence, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model.decode(inputs)\n",
    "    predictions = pred[0].tolist()\n",
    "    pred_label = []\n",
    "    inputs_with_offsets = tokenizer(sentence, return_offsets_mapping=True)\n",
    "    tokens = inputs_with_offsets.tokens()\n",
    "    offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "    idx = 0\n",
    "    while idx < len(predictions):\n",
    "        pred = predictions[idx]\n",
    "        label = id2label[pred]\n",
    "        if label != \"O\":\n",
    "            label = label[2:] # Remove the B- or I-\n",
    "            start, end = offsets[idx]\n",
    "            while (\n",
    "                idx + 1 < len(predictions) and \n",
    "                id2label[predictions[idx + 1]] == f\"I-{label}\"\n",
    "            ):\n",
    "                # all_scores.append(probabilities[idx + 1][predictions[idx + 1]])\n",
    "                _, end = offsets[idx + 1]\n",
    "                idx += 1\n",
    "            word = sentence[start:end]\n",
    "            pred_label.append(\n",
    "                {\n",
    "                    \"entity_group\": label,\n",
    "                    \"word\": word,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                }\n",
    "            )\n",
    "        idx += 1\n",
    "    print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf72fed-5acf-430d-a25b-acc80e67b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(valid_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d57aea-04bd-47ff-ad75-7350917c2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 打印模型的 state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # 打印优化器的 state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ad165-04a4-4087-8fc3-bdf7df7bb5db",
   "metadata": {},
   "source": [
    "# 保存/加载 state_dict（推荐）\n",
    "要注意这个细节，如果使用nn.DataParallel在一台电脑上使用了多个GPU，那么加载模型的时候也必须先进行nn.DataParallel。\n",
    "\n",
    "保存模型的推理过程的时候，只需要保存模型训练好的参数，使用torch.save()保存state_dict，能够方便模型的加载。因此推荐使用这种方式进行模型保存。\n",
    "\n",
    "记住一定要使用model.eval()来固定dropout和归一化层，否则每次推理会生成不同的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f935cee-82e4-4c53-b0ad-30b1f5fda3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存：\n",
    "torch.save(model.state_dict(), './model1')\n",
    "# 加载：\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load('./model1'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5023cbb-cde1-41c5-9d12-66bee4128164",
   "metadata": {},
   "source": [
    "# 保存/加载整个模型\n",
    "这种保存/加载模型的过程使用了最直观的语法，所用代码量少。这使用Python的pickle保存所有模块。这种方法的缺点是，保存模型的时候，序列化的数据被绑定到了特定的类和确切的目录。这是因为pickle不保存模型类本身，而是保存这个类的路径，并且在加载的时候会使用。因此，当在其他项目里使用或者重构的时候，加载模型的时候会出错。\n",
    "\n",
    "一般来说，PyTorch的模型以.pt或者.pth文件格式保存。\n",
    "\n",
    "一定要记住在评估模式的时候调用model.eval()来固定dropout和批次归一化。否则会产生不一致的推理结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67061c4-7247-4791-a7e7-8f8b8e86bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存：\n",
    "# torch.save(model, './model1')\n",
    "# # 加载：\n",
    "# model = torch.load('./model1')\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccea587-9774-49a8-bf7c-04e950ccd6c4",
   "metadata": {},
   "source": [
    "# 保存加载用于推理的常规Checkpoint/或继续训练\n",
    "在保存用于推理或者继续训练的常规检查点的时候，除了模型的state_dict之外，还必须保存其他参数。保存优化器的state_dict也非常重要，因为它包含了模型在训练时候优化器的缓存和参数。除此之外，还可以保存停止训练时epoch数，最新的模型损失，额外的torch.nn.Embedding层等。\n",
    "\n",
    "要保存多个组件，则将它们放到一个字典中，然后使用torch.save()序列化这个字典。一般来说，使用.tar文件格式来保存这些检查点。\n",
    "\n",
    "加载各个组件，首先初始化模型和优化器，然后使用torch.load()加载保存的字典，然后可以直接查询字典中的值来获取保存的组件。\n",
    "\n",
    "同样，评估模型的时候一定不要忘了调用model.eval()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234c23d-9cf9-4fc2-bdee-9ffe1b2a6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存：\n",
    "# torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss,\n",
    "#             ...\n",
    "#             }, './model1')\n",
    "# # 加载：\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# model.eval()\n",
    "# # - 或者 -\n",
    "# model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
